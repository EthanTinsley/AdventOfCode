{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code 2024 Day 9 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aocd import get_data, submit\n",
    "\n",
    "day = 9\n",
    "year = 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('example.txt', 'r') as file:\n",
    "    raw_sample_data = \"\".join(file.readlines())\n",
    "\n",
    "raw_sample_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_data = get_data(day=day, year=year)\n",
    "\n",
    "raw_test_data[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(raw_data:str):\n",
    "    return [int(x) for x in raw_data] \n",
    "\n",
    "sample_data = parse_data(raw_sample_data)\n",
    "test_data = parse_data(raw_test_data)\n",
    "\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part One!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_sample_data = False\n",
    "part = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sample_data if use_sample_data else test_data\n",
    "\n",
    "str(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union, Literal\n",
    "\n",
    "MemoryBlock = Union[int, Literal['.']]\n",
    "Memory = List[MemoryBlock]\n",
    "\n",
    "FileInfo = Dict[int, Dict[str, int]]\n",
    "FreeSpaceInfo = Dict[int, List[int]]\n",
    "\n",
    "StorageInfo = Dict[Union[Literal['freespace', 'files', 'max_file_size', 'max_freespace_size']], Union[Dict[int, FileInfo], FreeSpaceInfo]]\n",
    "\n",
    "\n",
    "def is_freespace(block:MemoryBlock):\n",
    "    return block == '.'\n",
    "\n",
    "def is_filespace(block:MemoryBlock):\n",
    "    return not is_freespace(block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memory(discrete_representation: list[int]) -> Memory:\n",
    "    memory = []\n",
    "\n",
    "    for i in range(len(discrete_representation)):\n",
    "        load_file = i % 2 == 0\n",
    "        file_idx = i // 2\n",
    "        block = file_idx if load_file else '.'\n",
    "        memory += [block] * discrete_representation[i]\n",
    "    \n",
    "    return memory\n",
    "\n",
    "load_memory(data)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def load_storage_info(discrete_representation: list[int]) -> StorageInfo:\n",
    "    storage_info: StorageInfo = {'files': {}, 'freespace': {}, 'max_file_size': 0, 'max_freespace_size': 0}\n",
    "    offset = 0\n",
    "\n",
    "    for i, block_size in enumerate(discrete_representation):\n",
    "        load_file = i % 2 == 0\n",
    "        idx = i // 2\n",
    "        \n",
    "        if load_file:\n",
    "            storage_info['files'][idx] = {\n",
    "                'file_location': offset,\n",
    "                'file_size': block_size\n",
    "            }\n",
    "\n",
    "            if block_size > storage_info['max_file_size']:\n",
    "                storage_info['max_file_size'] = block_size\n",
    "        \n",
    "        else:\n",
    "            storage_info['freespace'].setdefault(block_size, [])\n",
    "            heapq.heappush(storage_info['freespace'][block_size], offset)\n",
    "            \n",
    "            if block_size > storage_info['max_freespace_size']:\n",
    "                storage_info['max_freespace_size'] = block_size\n",
    "\n",
    "        offset += block_size\n",
    "    \n",
    "    return storage_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_memory_with_file_fragmentation(memory: list[MemoryBlock], storage_info: dict[int: int]) ->  Memory:\n",
    "    optimized_memory = memory[:]\n",
    "\n",
    "    i, j = 0, len(memory) - 1\n",
    "\n",
    "    while i < j:\n",
    "        frontblock, endblock = optimized_memory[i], optimized_memory[j]\n",
    "\n",
    "        if is_filespace(frontblock):\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        elif is_freespace(endblock):\n",
    "            j -= 1\n",
    "            continue\n",
    "\n",
    "        optimized_memory[i] = optimized_memory[j]\n",
    "        optimized_memory[j] = '.'\n",
    "\n",
    "        i += 1\n",
    "        j -= 1\n",
    "\n",
    "    return optimized_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_memory_without_file_fragmentation(memory: list[MemoryBlock], storage_info: StorageInfo) -> Memory:\n",
    "    optimized_memory = memory[:]\n",
    "    get_candidate_freespace_sizes = lambda size: ( k for k in storage_info['freespace'] if k >= size and len(storage_info['freespace'][k]) > 0 )\n",
    "\n",
    "    for file, file_info in reversed(storage_info['files'].items()):\n",
    "        file_size = file_info['file_size']\n",
    "        file_location = file_info['file_location']\n",
    "\n",
    "        for freespace_size in sorted(get_candidate_freespace_sizes(file_size), key=lambda k: storage_info['freespace'][k][0]):\n",
    "            if freespace_size < file_size:\n",
    "                continue\n",
    "            \n",
    "            if (storage_info['freespace'][freespace_size][0] >= file_location):\n",
    "                continue\n",
    "\n",
    "            idx = heapq.heappop(storage_info['freespace'][freespace_size])\n",
    "            for offset in range(file_size):\n",
    "                optimized_memory[idx + offset] = file\n",
    "                optimized_memory[file_location + offset] = '.'\n",
    "            \n",
    "            heapq.heappush(storage_info['freespace'][file_size], file_location)\n",
    "            \n",
    "            if file_size != freespace_size:\n",
    "                leftover_freespace = freespace_size - file_size\n",
    "                leftover_idx = idx + file_size\n",
    "                storage_info['freespace'].setdefault(leftover_freespace, [])\n",
    "                heapq.heappush(storage_info['freespace'][leftover_freespace], leftover_idx)\n",
    "            \n",
    "            break\n",
    "        \n",
    "    return optimized_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_memory(memory: list[MemoryBlock], storage_info: dict[int: int], file_fragmentation=True) -> Memory:\n",
    "    if file_fragmentation:\n",
    "        return optimize_memory_with_file_fragmentation(memory=memory, storage_info=storage_info)\n",
    "        \n",
    "    else:\n",
    "        return optimize_memory_without_file_fragmentation(memory=memory, storage_info=storage_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_checksum(memory: list[MemoryBlock]) -> int:\n",
    "    checksum = 0\n",
    "    for i, block in enumerate(memory):\n",
    "        checksum += block * i if is_filespace(block) else 0\n",
    "    \n",
    "    return checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_info = load_storage_info(data)\n",
    "\n",
    "memory = load_memory(data)\n",
    "\n",
    "optimized_memory = optimize_memory(memory, storage_info)\n",
    "\n",
    "checksum = generate_checksum(optimized_memory)\n",
    "\n",
    "part_a_answer = checksum\n",
    "part_a_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_sample_data and part == 'a':\n",
    "    submit(answer=part_a_answer, part='a', day=day, year=year, reopen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_sample_data = False\n",
    "part='b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sample_data if use_sample_data else test_data\n",
    "\n",
    "str(data[:100]), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_info = load_storage_info(data)\n",
    "\n",
    "memory = load_memory(data)\n",
    "\n",
    "optimized_memory = optimize_memory(memory, storage_info, file_fragmentation=False)\n",
    "\n",
    "checksum = generate_checksum(optimized_memory)\n",
    "\n",
    "part_b_answer = checksum\n",
    "part_b_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_sample_data and part == 'b':\n",
    "    submit(answer=part_b_answer, part='b', day=day, year=year, reopen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Results \n",
    "\n",
    "The initial approach for Part 2's optimization without file fragmentation was let's say, less that optimal.... On the test data it was able to correctly optimize the memory but runs for a whopping 1.5 minutes. As such I spent some time optimizing the solution to make use of a tabulated set of freespace positions. Each size of freespace (0 - 9) has an associated heap. By compaing the top of the heap (peeking) of the freespace sizes that would fit the file we are able to quickly retrieve the location that the file is supposed to move to. This removes a linear scan of all the memory for each file and cuts down the runtime drastically. \n",
    "\n",
    "This section showcases the two times using %timeit for comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original un-optimal implementation. (it is clean tho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_memory_without_file_fragmentation_original(memory: list[MemoryBlock], storage_info: dict[int: int]) -> list[MemoryBlock]:\n",
    "    optimized_memory = memory[:]\n",
    "\n",
    "    for file, file_info in reversed(storage_info['files'].items()):\n",
    "        file_size = file_info['file_size']\n",
    "        j = file_info['file_location']\n",
    "\n",
    "        for i in range(len(optimized_memory)):\n",
    "            if i >= j:\n",
    "                break\n",
    "\n",
    "            memory_slice = optimized_memory[i:i + file_size]\n",
    "            is_freespace_available = all([ is_freespace(x) for x in memory_slice])\n",
    "\n",
    "            if not is_freespace_available:\n",
    "                continue\n",
    "\n",
    "            for offset in range(file_size):\n",
    "                optimized_memory[i + offset] = file\n",
    "                optimized_memory[j + offset] = '.'\n",
    "            \n",
    "            break\n",
    "    \n",
    "    return optimized_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the un-optimzied approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.5 s ± 286 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit optimize_memory_without_file_fragmentation_original(load_memory(data), load_storage_info(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Optimized approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.9 ms ± 150 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit optimize_memory_without_file_fragmentation(load_memory(data), load_storage_info(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
